[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "",
    "text": "Welcome to our project page.\nBegum CORUH & Eda GONEN\nKeep an eye on this space to stay updated with my project activities."
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project X",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nxxxxxx"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project X",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nxxxxxx"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project X",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nxxxxxx"
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project X",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nxxxxxx"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Begüm’s Analytics Lab",
    "section": "",
    "text": "Hello!! My name is Begüm\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nPi Makina, Production Planning Intern, 2022\nVakıfbank, Buisness Analyst Intern, 2023\nNurol Teknoloji, Project Intern, 2024"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Veri Bilimi ve Endüstri Mühendisliği Üzerine Sohbetler - Mustafa Baydoğan & Erdi Daşdemir\nMustafa Baydoğan and Erdi Daşdemir discuss various topics related to data science and industrial engineering in their YouTube chats. They share their background and experience in the field, including data analysis, machine learning and optimisation research. Another topic they addressed was the preference for certain types of wood in the construction industry, namely straight and trapezoidal timber. They emphasised the importance of understanding the underlying reasons for these characteristics in order to use wood effectively in construction projects. The talk also covered the importance of data pre-processing, especially in the context of image analysis, machine learning algorithms, and the differences between traditional and deep learning. They discussed the importance of understanding the problem at hand and selecting appropriate machine learning techniques to create effective industry solutions. In addition, they emphasised the importance of making accurate predictions in the market to maintain balance. Overall, they emphasised the importance of both traditional and deep learning methods in data science and the importance of understanding the underlying problem at hand and choosing the appropriate techniques to create effective industry solutions. They also explore methods to minimise errors in regression analysis and to improve optimisation methods used in machine learning. They talk about the importance of gaining expertise in data science through practical applications, experience and formal education. In another part of the talk, they share their experiences in the energy sector and participate in forecasting competitions. They emphasise the importance of continuous learning, collaboration and knowledge sharing on the web. Throughout the talk, they emphasise the importance of starting early, being persistent and staying up-to-date with the latest research and technologies in their field.\nMTCARS Analizi\n\nlibrary(dslabs)\ndata(mtcars)\n#compute_stats fonksiyonunu oluşturuldu\ncompute_stats &lt;- function(x) {\n  if (!is.numeric(x)) {\n    stop(\"Girdi sayısal bir vektör olmalıdır.\") #Input değeri vektör değilse fonksiyonu durduracak şekilde koşullu durum eklendi\n  }\n  #İstenilen istatistiksel değerler liste haline getirildi\n  statistics_list &lt;- list(\n    mean = mean(x),       # Ortalama değer\n    median = median(x),   # Medyan değeri\n    variance = var(x),    # Varyans değeri\n    IQR = IQR(x),         # Çeyrekler arası açıklık (IQR) değeri\n    min = min(x),         # Minimum değer\n    max = max(x)          # Maksimum değer\n  )\n  \n  return(statistics_list)\n}\n\n# mtcars veri setindeki 'hp' sütunu üzerinde fonksiyonu test edelim\nresult &lt;- compute_stats(mtcars$hp)\n# Sonuçları ekrana yazdıralım\nprint(result)\n\n$mean\n[1] 146.6875\n\n$median\n[1] 123\n\n$variance\n[1] 4700.867\n\n$IQR\n[1] 83.5\n\n$min\n[1] 52\n\n$max\n[1] 335\n\n\n\ndata(mtcars)\n\n#compute_stats fonksiyonunu oluşturuldu\ncompute_stats &lt;- function(x) {\n  \n  statistics_list &lt;- list(\n    mean = mean(x),       # Ortalama değer\n    median = median(x),   # Medyan değeri\n    variance = var(x),    # Varyans değeri\n    IQR = IQR(x),         # Çeyrekler arası açıklık (IQR) değeri\n    min = min(x),         # Minimum değer\n    max = max(x)          # Maksimum değer\n  )\n  \n  return(statistics_list)\n}\n\n# Her satırın istatistiksel değerleri için for döngüsü eklendi\nfor (column_name in colnames(mtcars)) {\n  \n  \n\n    # Sütun adıyla birlikte sonuçlar yazdırıldı\n    print(paste(column_name,\"icin istatistikler\"))\n    print(compute_stats(mtcars$mpg))\n}\n\n[1] \"mpg icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"cyl icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"disp icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"hp icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"drat icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"wt icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"qsec icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"vs icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"am icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"gear icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n[1] \"carb icin istatistikler\"\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$IQR\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\n\nlibrary(dslabs)\ndata(mtcars)\ncompute_stats &lt;- function(x) {\n  #birden fazla değeri c'de birleştirdik\n  c(mean = mean(x), \n    median = median(x), \n    variance = var(x), \n    IQR = IQR(x), \n    min = min(x), \n    max = max(x))\n}\n\n# Fonksiyonu tüm satırlar için uygula\nsapply(mtcars, compute_stats)\n\n              mpg      cyl       disp        hp      drat       wt      qsec\nmean     20.09062 6.187500   230.7219  146.6875 3.5965625 3.217250 17.848750\nmedian   19.20000 6.000000   196.3000  123.0000 3.6950000 3.325000 17.710000\nvariance 36.32410 3.189516 15360.7998 4700.8669 0.2858814 0.957379  3.193166\nIQR       7.37500 4.000000   205.1750   83.5000 0.8400000 1.028750  2.007500\nmin      10.40000 4.000000    71.1000   52.0000 2.7600000 1.513000 14.500000\nmax      33.90000 8.000000   472.0000  335.0000 4.9300000 5.424000 22.900000\n                vs        am      gear     carb\nmean     0.4375000 0.4062500 3.6875000 2.812500\nmedian   0.0000000 0.0000000 4.0000000 2.000000\nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1.0000000 1.0000000 1.0000000 2.000000\nmin      0.0000000 0.0000000 3.0000000 1.000000\nmax      1.0000000 1.0000000 5.0000000 8.000000\n\n# Fonksiyonu tüm satırlar için uygula (satır bazlı işlemlerde margin değeri 1 alınır, sütün bazlı işlemlerde ise 2)\napply(mtcars,2,  compute_stats)\n\n              mpg      cyl       disp        hp      drat       wt      qsec\nmean     20.09062 6.187500   230.7219  146.6875 3.5965625 3.217250 17.848750\nmedian   19.20000 6.000000   196.3000  123.0000 3.6950000 3.325000 17.710000\nvariance 36.32410 3.189516 15360.7998 4700.8669 0.2858814 0.957379  3.193166\nIQR       7.37500 4.000000   205.1750   83.5000 0.8400000 1.028750  2.007500\nmin      10.40000 4.000000    71.1000   52.0000 2.7600000 1.513000 14.500000\nmax      33.90000 8.000000   472.0000  335.0000 4.9300000 5.424000 22.900000\n                vs        am      gear     carb\nmean     0.4375000 0.4062500 3.6875000 2.812500\nmedian   0.0000000 0.0000000 4.0000000 2.000000\nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1.0000000 1.0000000 1.0000000 2.000000\nmin      0.0000000 0.0000000 3.0000000 1.000000\nmax      1.0000000 1.0000000 5.0000000 8.000000\n\n\nNA Example\n\nlibrary(dslabs)\n\n# na_example veri setini yükle\ndata(\"na_example\")\n\n# Veri setini görüntüle\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\nlibrary(dslabs)\ndata(na_example)\n\n# NA değerlerinin toplam sayısını bul\ntotal_na &lt;- sum(is.na(na_example))\ntotal_na  # Toplam NA sayısını ekrana yazdırır\n\n[1] 145\n\n# NA değerlerinin indekslerini bul\nna_indices &lt;- which(is.na(na_example))\nna_indices  # NA değerlerinin indeks pozisyonlarını ekrana yazdırır\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\nlibrary(dslabs)\ndata(na_example)\n\n# NA değerleri göz ardı edilerek ortalama ve standart sapma hesapla\nmean &lt;- mean(na_example, na.rm = TRUE)\nstd_dev &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonuçları görüntüle\nmean\n\n[1] 2.301754\n\nstd_dev\n\n[1] 1.22338\n\n\n\nlibrary(dslabs)\ndata(na_example)\n\n# NA değerlerinin medyan ile değiştirilmesi\nreplace_na_with_median &lt;- function(x) {\n  # Sadece NA değerlerinin olduğu kısımları medyan ile değiştir\n  median_value &lt;- median(x, na.rm = TRUE)  # NA'ları göz ardı ederek medyan hesapla\n  x[is.na(x)] &lt;- median_value  # NA olan yerleri medyan ile değiştir\n  return(x)\n}\n\n# Version 1: NA'ları medyan ile değiştirilmiş veri seti\nna_example&lt;- replace_na_with_median(na_example)\n\n# Sonuçları göster\nna_example\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nlibrary(dslabs)\ndata(na_example)\n\n# NA değerlerini rastgele bir non-NA değer ile değiştirme fonksiyonu\nreplace_na_with_random &lt;- function(x) {\n  # Geçerli (non-NA) değerleri al\n  non_na_values &lt;- x[!is.na(x)]\n  \n  # Eğer hiç geçerli değer yoksa hata verme\n  if (length(non_na_values) == 0) {\n    stop(\"Veri setinde hiç geçerli (non-NA) değer bulunamadı.\")\n  }\n  \n  # Her NA değerine rastgele bir non-NA değer atama\n  x[is.na(x)] &lt;- sample(non_na_values, sum(is.na(x)), replace = TRUE)\n  return(x)\n}\n\n# Version 2: NA'ları rastgele bir geçerli değer ile değiştirilmiş veri seti\nna_example &lt;- replace_na_with_random(na_example)\n\n# Sonuçları göster\nprint(na_example)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 3 2 2 1 4 3 1 1 2 1 2 2 1 2 5 1 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 1 2 2 1 1 5 1 3 1 1 4 4 7 3 2 4 3 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 1 5 1 1 1 5 1 2 1 3 5 3 2 2 1 1 1 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 1 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 4 4 3 1 4 1 1\n [186] 3 1 1 1 2 3 5 2 2 2 3 1 2 2 3 2 1 1 2 1 1 2 3 2 1 1 5 3 1 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 4 5 1 4 1 3 1 1 1 1 5 2 3 3 2 4 3 3 2 5 2 2 3\n [260] 4 6 2 2 2 1 2 4 2 3 3 3 2 2 4 3 1 4 2 1 2 4 3 6 2 3 1 4 2 2 1 1 1 3 2 3 3\n [297] 1 5 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 1 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 1 1 2 1 1 3 3 3 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 4 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 1 3 3 4 2 2 1 2 1 1 4 2 1 4 4 3\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 1 4 4 4 1 1 1 4\n [445] 3 1 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 4 3 2 1 1 2 3 2 2 2 3 3 1 1 2 1 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 3 1 1 3 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 1 2 3 2 1 2 1 1 1 2 2 3 1 5 2 1 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 1 3 2 3 3 4 2 3 2 4 4 4 1 1 2 2 3 1 1 1 3\n [630] 5 2 5 3 7 1 3 4 3 3 1 1 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 1\n [667] 2 2 6 3 3 1 4 4 2 1 1 1 6 3 3 3 2 1 1 6 3 1 5 1 4 2 6 2 2 4 1 3 1 2 1 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 1 2 2 4 3 3 3\n [741] 2 4 2 4 2 1 3 3 2 1 3 2 4 3 2 1 2 3 1 3 4 1 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 3 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 3 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 1 1 3 1 2 1 1 2 1 2 1 2 1 3 2 3 2 3 2 1 4 2 5 1 1 2 4 2 3 3 3\n [852] 1 3 5 5 2 2 2 4 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 4 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 1 3 2 1 1 1 2 1 2 2 3 3 2 1 4\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 1 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 1 1 2 2 3 1 1 2 5 3 5 1 1 4 1 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 3\n[1000] 2\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g. Spring 2024-2025] EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "project.html#project-overview-and-scope",
    "href": "project.html#project-overview-and-scope",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "1.Project Overview and Scope",
    "text": "1.Project Overview and Scope\nIn this project, we aim to analyze how different movie genres perform in terms of audience preferences. Our primary focus is to identify genre-based patterns in film popularity and ratings, using a data-driven approach. To make the analysis more meaningful and localized, we enriched a widely-used global movie dataset by merging it with a Turkish-specific movie dataset. Through this project, we plan to discover whether certain genres are more successful among audiences and if factors like production year, runtime, or budget have a significant effect on genre-based popularity."
  },
  {
    "objectID": "project.html#data",
    "href": "project.html#data",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "2.Data",
    "text": "2.Data\nWe based our analysis on a combined dataset. The core dataset is ggplot2movies, which includes information about thousands of films worldwide.\nTo create a more localized perspective, we merged this dataset with a Turkish movie dataset.\nThe combined data allowed us to create new variables, such as Turkish-specific ratings and popularity scores, which we will use in our comparative analysis.\n\n2.1 Data Source\n\nThe global movie data is sourced from the open-access ggplot2movies dataset, widely used in data analysis and visualization projects.\nThe Turkish-specific data was obtained from Kaggle, specifically from the Turkish Movies Dataset shared by Emre OkC’ular.\nBoth datasets provide rich information such as film titles, genres, production years, runtimes, IMDb ratings, and other useful attributes for our analysis.\n\n\n\n2.2 Reasons of Choice\nWe selected this dataset because it offers a rich and diverse set of information about movies across different genres and periods. The global ggplot2movies dataset provides a well-organized structure for large-scale analysis, while the Turkish Movies dataset adds a localized dimension to the study, making it more relevant to regional audience preferences. The combination of both datasets allows us to explore general trends as well as cultural differences in movie genre popularity. Moreover, the variety of available variables such as genre, rating, year, runtime, and awards creates multiple opportunities for deeper analytical approaches.\n\n\n2.3 Data Combination Process & Preprocessing\nTo create a comprehensive and diverse dataset, we combined two different sources.\nFirst, we imported the original ggplot2movies dataset, which contains global movie information including variables such as title, year, length, budget, rating, votes, and genre indicators.\nSecond, we processed a Turkish movie dataset, cleaned it, and expanded its structure to match the global dataset’s format.\nWe standardized column names, added missing fields where necessary (e.g., budget, votes, genre dummies), and included a country variable to distinguish between Global and Turkish movies.\nAfter ensuring consistency across both datasets, we merged them into a single, unified dataset named combined_movies.\nThis final dataset preserves authentic movie titles and metadata while also incorporating localized Turkish film information, making it suitable for international and regional analyses.\nThe combined dataset was saved in both .RData and .csv formats for flexibility in further exploration and analysis.\n\n# 1. Global movies verisini yukle\nload(\"movies.RData\")\n\n# 2. Turkish movies verisini oku\nturkish_movies &lt;- read.csv(\"final_dataset.csv\", fileEncoding = \"UTF-8\")\n\n# 3. Turkish movies verisini genislet\nturkish_movies_expanded &lt;- data.frame(\n  title = turkish_movies$localized.title,\n  year = as.integer(turkish_movies$runtimes),\n  length = as.integer(turkish_movies$runtimes),\n  budget = NA,\n  rating = turkish_movies$rating,\n  votes = NA,\n  r1 = NA, r2 = NA, r3 = NA, r4 = NA, r5 = NA, \n  r6 = NA, r7 = NA, r8 = NA, r9 = NA, r10 = NA,\n  mpaa = NA,\n  Action = NA, Animation = NA, Comedy = NA, Drama = NA,\n  Documentary = NA, Romance = NA, Short = NA,\n  country = \"Turkey\"\n)\n\n# 4. Global movies'a country kolonu ekle\nmovies$country &lt;- \"Global\"\n\n# 5. Kolon sD1ralarD1nD1 esitle\nturkish_movies_expanded &lt;- turkish_movies_expanded[, names(movies)]\n\n# 6. Ikisini birlestir\ncombined_movies &lt;- rbind(movies, turkish_movies_expanded)\n\n# 7. Kaydet\nsave(combined_movies, file = \"combined_movies.RData\")\n\n# 8. CSV de olustur\nwrite.csv(combined_movies, file = \"combined_movies.csv\", row.names = FALSE)\n\n\n\n2.4 Data Summary\nThe final dataset combines global and Turkish movies, resulting in a comprehensive collection of approximately 8,000 films.\nIt includes a wide range of information for each movie, covering basic metadata, audience ratings, and genre classifications.\nThe following code blocks provide an overview of the combined movies dataset, including its structure, dimensions, variable names, sample records, and distribution patterns.\n\nStructure of combined_movies dataset\n\n# Load the combined dataset\nload(\"combined_movies.RData\")\n\n# Show structure\nstr(combined_movies)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   67465 obs. of  25 variables:\n $ title      : chr  \"$\" \"$1000 a Touchdown\" \"$21 a Day Once a Month\" \"$40,000\" ...\n $ year       : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...\n $ length     : int  121 71 7 70 71 91 93 25 97 61 ...\n $ budget     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ rating     : num  6.4 6 8.2 8.2 3.4 4.3 5.3 6.7 6.6 6 ...\n $ votes      : int  348 20 5 6 17 45 200 24 18 51 ...\n $ r1         : num  4.5 0 0 14.5 24.5 4.5 4.5 4.5 4.5 4.5 ...\n $ r2         : num  4.5 14.5 0 0 4.5 4.5 0 4.5 4.5 0 ...\n $ r3         : num  4.5 4.5 0 0 0 4.5 4.5 4.5 4.5 4.5 ...\n $ r4         : num  4.5 24.5 0 0 14.5 14.5 4.5 4.5 0 4.5 ...\n $ r5         : num  14.5 14.5 0 0 14.5 14.5 24.5 4.5 0 4.5 ...\n $ r6         : num  24.5 14.5 24.5 0 4.5 14.5 24.5 14.5 0 44.5 ...\n $ r7         : num  24.5 14.5 0 0 0 4.5 14.5 14.5 34.5 14.5 ...\n $ r8         : num  14.5 4.5 44.5 0 0 4.5 4.5 14.5 14.5 4.5 ...\n $ r9         : num  4.5 4.5 24.5 34.5 0 14.5 4.5 4.5 4.5 4.5 ...\n $ r10        : num  4.5 14.5 24.5 45.5 24.5 14.5 14.5 14.5 24.5 4.5 ...\n $ mpaa       : chr  \"\" \"\" \"\" \"\" ...\n $ Action     : int  0 0 0 0 0 0 1 0 0 0 ...\n $ Animation  : int  0 0 1 0 0 0 0 0 0 0 ...\n $ Comedy     : int  1 1 0 1 0 0 0 0 0 0 ...\n $ Drama      : int  1 0 0 0 0 1 1 0 1 0 ...\n $ Documentary: int  0 0 0 0 0 0 0 1 0 0 ...\n $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Short      : int  0 0 1 0 0 0 0 1 0 0 ...\n $ country    : chr  \"Global\" \"Global\" \"Global\" \"Global\" ...\n\n\n\n\nNumber of rows and columns\n\n# Number of rows and columns\ndim(combined_movies)\n\n[1] 67465    25\n\n\n\n\nNames of variables\n\n# Names of variables\nnames(combined_movies)\n\n [1] \"title\"       \"year\"        \"length\"      \"budget\"      \"rating\"     \n [6] \"votes\"       \"r1\"          \"r2\"          \"r3\"          \"r4\"         \n[11] \"r5\"          \"r6\"          \"r7\"          \"r8\"          \"r9\"         \n[16] \"r10\"         \"mpaa\"        \"Action\"      \"Animation\"   \"Comedy\"     \n[21] \"Drama\"       \"Documentary\" \"Romance\"     \"Short\"       \"country\"    \n\n\n\n\nFirst 6 rows of data\n\n# First 6 rows of data\nhead(combined_movies)\n\n                     title year length budget rating votes   r1   r2  r3   r4\n1                        $ 1971    121     NA    6.4   348  4.5  4.5 4.5  4.5\n2        $1000 a Touchdown 1939     71     NA    6.0    20  0.0 14.5 4.5 24.5\n3   $21 a Day Once a Month 1941      7     NA    8.2     5  0.0  0.0 0.0  0.0\n4                  $40,000 1996     70     NA    8.2     6 14.5  0.0 0.0  0.0\n5 $50,000 Climax Show, The 1975     71     NA    3.4    17 24.5  4.5 0.0 14.5\n6                    $pent 2000     91     NA    4.3    45  4.5  4.5 4.5 14.5\n    r5   r6   r7   r8   r9  r10 mpaa Action Animation Comedy Drama Documentary\n1 14.5 24.5 24.5 14.5  4.5  4.5           0         0      1     1           0\n2 14.5 14.5 14.5  4.5  4.5 14.5           0         0      1     0           0\n3  0.0 24.5  0.0 44.5 24.5 24.5           0         1      0     0           0\n4  0.0  0.0  0.0  0.0 34.5 45.5           0         0      1     0           0\n5 14.5  4.5  0.0  0.0  0.0 24.5           0         0      0     0           0\n6 14.5 14.5  4.5  4.5 14.5 14.5           0         0      0     1           0\n  Romance Short country\n1       0     0  Global\n2       0     0  Global\n3       0     1  Global\n4       0     0  Global\n5       0     0  Global\n6       0     0  Global"
  },
  {
    "objectID": "project.html#data-analysis",
    "href": "project.html#data-analysis",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "3.Data Analysis",
    "text": "3.Data Analysis\nThe analyses presented here are intended solely for illustrative purposes and do not represent a definitive study.\n\nTop 10 Highest Rated Movies\n\ninstall.packages(\"dplyr\", repos = \"https://cloud.r-project.org\")\n\nInstalling package into 'C:/Users/begum/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\npackage 'dplyr' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\begum\\AppData\\Local\\Temp\\RtmpUdU5GC\\downloaded_packages\n\ninstall.packages(\"ggplot2\", repos = \"https://cloud.r-project.org\")\n\nInstalling package into 'C:/Users/begum/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\npackage 'ggplot2' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\begum\\AppData\\Local\\Temp\\RtmpUdU5GC\\downloaded_packages\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Top 10 Movies Rating Line Chart \nmovies %&gt;%\n  filter(rating &gt; 0) %&gt;%\n  arrange(desc(rating)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(title = factor(title, levels = title)) %&gt;%\n  ggplot(aes(x = title, y = rating, group = 1, color = factor(year))) +\n  geom_line(size = 1) +    \n  geom_point(size = 3) +\n  labs(title = \"Top 10 Highest Rated Movies (Line Chart)\",\n       x = \"Movie Title\",\n       y = \"IMDb Rating\") +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nIn this line chart, the same top 10 movies are displayed sequentially based on their ratings. The downward movement highlights the slight decrease between consecutive IMDb ratings. Coloring by release year shows the temporal diversity among the highest-rated films.\n\n\nAverage Rating and Runtime by Country\n\ncombined_movies %&gt;%\n  group_by(country) %&gt;%\n  summarize(\n    Average_Rating = round(mean(rating, na.rm = TRUE), 2),\n    Average_Length = round(mean(length, na.rm = TRUE), 1)\n  )\n\n# A tibble: 2 × 3\n  country Average_Rating Average_Length\n  &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Global            5.93           82.3\n2 Turkey            5.52           90.3\n\n\n\n\nComparison of IMDb Ratings: Global vs Turkey\n\n# Sahte bir ulke atamasi \nset.seed(42)\nmovies_grouped &lt;- movies %&gt;%\n  filter(!is.na(rating), !is.na(length)) %&gt;%\n  mutate(country = ifelse(runif(n()) &gt; 0.95, \"Turkey\", \"Global\"))\n\n# Boxplot: Rating vs Country\nggplot(movies_grouped, aes(x = country, y = rating, fill = country)) +\n  geom_boxplot(outlier.shape = 21, outlier.fill = \"white\", outlier.color = \"black\", width = 0.6) +\n  scale_fill_manual(values = c(\"Global\" = \"#3498db\", \"Turkey\" = \"#e74c3c\")) +\n  labs(title = \"IMDb Rating Distribution by Country\",\n       subtitle = \"Comparison between Global and Turkey Films\",\n       x = \"Country\",\n       y = \"IMDb Rating\") +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis boxplot compares the IMDb rating distributions between films produced globally and those produced in Turkey. Turkish films show a narrower distribution, while global films cover a broader range of ratings. Mean differences and the presence of outliers provide further insights into rating variability between the two groups.\nTo be continued…"
  }
]